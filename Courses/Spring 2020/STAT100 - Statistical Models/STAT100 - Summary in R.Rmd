---
Summary of R codes for the course STAT100 at NMBU:
---

```{r}
# Read data from excel:
library(readxl)
data_xl <- read_excel("table.xlsx")

# Fraquency table of a variable:
frequency <- table(data_xl)

# Relative fraquency table of a variable:
# relative_frequency <- prop.table(data_xl)
# relative_frequency

# Number of rows:
# nrow(data_xl)

# Summary of the data:
# summary(data_xl)

# Plot examples:
# hist(x=pair_wised, main='Histogram for Distribution', xlab='Observations')
# boxplot(pair_wised, horizontal=TRUE, col='orange', add=TRUE)
# abline(v=mean(pair_wised), col='blue', lw=3)
# abline(v=1*sd(pair_wised), col='black', lw=3)
# abline(v=-1*sd(pair_wised), col='black', lw=3)
```

#The Normal distribution:
https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/Normal

```{r}
pop_mean = 1010
pop_std = 10

# The quantile function (z-score):
z_score <- qnorm(p=0.05, mean=0, sd=1, lower.tail=TRUE)
cat('z-score:', z_score)

# Proportion of z-score: lower.tail=TRUE: P(Z<=z) or lower.tail=FALSE:P(Z>z):
# The distribution function:
prop_z_score <- pnorm(q=z_score, mean=0, sd=1, lower.tail=TRUE)
cat('\nProportion of z-score:', prop_z_score)

# Limit k:
# z-score <- (k - pop.mean) / pop.std
k <- z_score * pop_std + pop_mean
cat('\nConversion and limit k:', k)
```

# The Binomial Distribution:
https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/Binomial

```{r}
pop_size = 10        # n
pop_prob = 0.1357    # sucess probability: p_hat = #X/n

# Convert binom(n,p) ~ nom(pop_mean, pop_std):
pop_mean <- pop_size*pop_prob                    # Expected value: n*p
pop_std <- sqrt(pop_size*pop_prob*(1-pop_prob))  # Standard deviation: sqrt(n*p(1-p))
```

# The T-student distribution:
https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/TDist

```{r}
dt(x, df, ncp)
pt(q, df, ncp, lower.tail = TRUE)
qt(p, df, ncp, lower.tail = TRUE)
rt(n, df, ncp)
```

# F-distribution:
https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/FDist

```{r}
df(x, df1, df2, ncp, log = FALSE)
pf(q, df1, df2, ncp, lower.tail = TRUE)
qf(p, df1, df2, ncp, lower.tail = TRUE)
rf(n, df1, df2, ncp)
```

# Pairwised or not pairwised Analysis -> t-test:
https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/t.test
https://www.statmethods.net/stats/ttest.html

```{r}
# Creating variables in columns:
Y1 <- c(1.94, 1.44, 1.56, 1.58, 2.06)
Y2 <- c(1.27, 1.63, 1.47, 1.39, 1.93)
pair_wised <- Y1 - Y2

# Pairwised degrees of freedom:  # 'two.sided', 'greater' or 'less'
t.test(Y1, Y2, mu=0, alternative='two.sided', paired=TRUE, var.equal=TRUE, conf.level=0.95)
```

```{r}
# Not pairwised degrees of freedom:  # 'two.sided', 'greater' or 'less'
t.test(Y1, Y2, mu=0, alternative='two.sided', paired=FALSE, var.equal=FALSE, conf.level=0.95)
```

# Contrast Analysis:
https://rdrr.io/cran/gmodels/man/fit.contrast.html

```{r}
# install.packages("gmodels")
library(gmodels, pos = 25)

# Creating variables in columns:
Y1 <- c(1.94, 1.44, 1.56, 1.58, 2.06)
Y2 <- c(1.27, 1.63, 1.47, 1.39, 1.93)
Y3 <- c(1.67, 1.33, 1.37, 1.29, 1.83)

# Creating data frame:
df1 <- data.frame(Y1, Y2, Y3)

# Stacking data frame:
df1_stack <-stack(df1)

# Creating model:
model1 = aov(formula=values~ind, data=df1_stack)

# Creating contrasts:
contrasts <- c(1/2, 1/2, -1)

# Fitting test:
fit.contrast(model=model1, varname="ind", df=TRUE, coeff=contrasts, conf.int=0.95)
```

# Analysis of Variance:

# One-way ANOVA:
https://www.statmethods.net/stats/anova.html

```{r}
# Creating variables in columns:
Y1 <- c(1.94, 1.44, 1.56, 1.58, 2.06)
Y2 <- c(1.27, 1.63, 1.47, 1.39, 1.93)

# Creating data frame:
df2 <- data.frame(Y1, Y2)

# Stacking data frame:
df2_stack <- stack(df2)

# Creating the model:
model2 <- aov(formula=values~ind, data=df2_stack)  # lm(Y_stack)

# Variance analysis for 2 factors:
anova(model2)
```

```{r}
# Exercise 1i):

########### Calculating Explained Sum of Square SSF:
SSF <- 0
k <- 2

for (i in 1:k){
  SSF <- SSF + (nrow(df[i]) * ( mean(df[ , i]) - mean(Y_stack$values) )^2 )
}

SSF_df = k-1
MSF <- SSF/SSF_df

cat("The Explained Sum of Square is ", SSF, "\nThe ESS's degree of freedom is ", SSF_df, 
    "\nThe Mean Square Factor MSF is ", MSF)

########### Calculating Residual Sum of Square RSS:
SSE <- 0
n <- 5

for (i in 1:k){
  for (j in 1:n){
    SSE <- SSE + (df[j , i] - mean(df[ , i]))^2
  }
}

SSE_df = k*n - k
MSE <- SSE/SSE_df
  
cat("\n\nThe Residual Sum of Square is ", SSE, "\nThe RSS's degree of freedom is ", SSE_df,
    "\nThe Mean Square Error MSE is ", MSE)

########### Calculating F-statistic:
cat("\n\nThe F-test = ", MSF/MSE)
cat("\n\nThe F_score = ", qf(0.95, SSF_df, SSE_df))
```

# Regression Analysis:

```{r}
# Regression Analysis:

# Creating variables:
x1 <- c(5, 5, 8, 8, 5, 8, 7, 7, 10, 10)
x2 <- c(59, 65, 128, 160, 76, 55, 82, 132, 116, 62)
y <- c(110, 136, 100, 90, 150, 99, 110, 90, 60, 128)

# Creating data frame:
df3 <- data.frame(x1, x2, y)

# Creating the model between y and x1:
model3 <- lm(df3$y~df3$x1, data=df3)

# Regression Analysis:
summary(model3)
```

# Chi squared distribution:
https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/Chisquare

```{r}
# Dependency analysis:

# Create a contingency table:
X <- c(rep("No", 82), rep("Yes", 133))
Y <- c(rep("CE", 22), rep("CI", 20), rep("DE",19), rep("DI", 21),  # No
       rep("CE", 25), rep("CI", 32), rep("DE",25), rep("DI", 51))  # Yes

contingency <- table(X, Y)

barplot(contingency, beside=TRUE, xlab="X", ylab="Y", legend=rownames(contingency))

chisq_test <- chisq.test(contingency, correct=FALSE)

summary(contingency)
cat("\n")

summary(chisq_test)
chisq_test

df <- 3  # k-1
alpha <- 0.95  # Security level ?
cat("\n", "Chisq quantile:", qchisq(p=alpha, df=df), "\n")
cat("\n", "Chisq probability:", pchisq(q=7.814728, df=df), "\n")

# Print E_i_j (expected contingency):
cat("\n", "Expected Contingency (E_i_j) table: ", "\n")
chisq_test$expected

# Print Q_i_j (contribution):
cat("\n", "Contribution (Q_i_j) table:", "\n")
(chisq_test$observed - chisq_test$expected)^2 / chisq_test$expected
```
